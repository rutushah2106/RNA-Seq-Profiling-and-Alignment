# -*- coding: utf-8 -*-
"""cs121 project - Rutu Shah

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mFAcOlPjjBvJJ42Mc0AxA5NpunBlzzqz
"""

# @title

# @title
222#imports
import pandas as pd
import numpy as np
import math
import random
from matplotlib import pyplot as plt

# @title
#getting canonical k-mer
def canonical(kmer):
    rc_kmer = reverse_complement(kmer)
    if kmer < rc_kmer:
        return kmer
    else:
        return rc_kmer

#getting reverse complement of k-mer
def reverse_complement(kmer):
    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}
    rc = ''.join([complement[base] for base in kmer[::-1]])
    return rc

# @title
# Define the FASTA database file name
fasta_file = "chr11_transcriptome.fasta"

# Initialize the hash table as a dictionary
hash_table = {}

# Open the FASTA file and iterate over the sequences
with open(fasta_file) as f:
    seq_id = None
    seq = ""
    for line in f:
        if line.startswith(">"):  # Start of a new sequence
            if seq_id is not None:  # Store the previous sequence's k-mers
                for i in range(len(seq) - 30):
                    kmer = canonical(seq[i:i+31])
                    gene_id_list = hash_table.get(kmer, [])
                    gene_id_list.append(seq_id)
                    hash_table[kmer] = gene_id_list
            seq_id = line.strip()[1:]
            seq = ""
        else:  # Sequence line
            seq += line.strip().upper()

    # Store the last sequence's k-mers
    for i in range(len(seq) - 30):
        kmer = canonical(seq[i:i+31])
        gene_id_list = hash_table.get(kmer, [])
        gene_id_list.append(seq_id)
        hash_table[kmer] = gene_id_list

# @title
# function to generate canonical k-mers
def generate_kmers(read, k):
    kmers = []
    for i in range(len(read) - k + 1):
        kmer = read[i:i+k]
        canonical_kmer = canonical(kmer)
        kmers.append(canonical_kmer)
    return kmers

#function to get equivalence class for a read
def get_equivalence_classes(read, hash_table, k):
  first_kmer = generate_kmers(read, k)[0]
  first_eq_class = hash_table.get(first_kmer, set())
  if not first_eq_class:
      return set()
  eq_classes = set(first_eq_class)
  for kmer in generate_kmers(read, k)[1:]:
      curr_eq_class = hash_table.get(kmer, set())
      if not curr_eq_class:
          return set()
      eq_classes.intersection_update(curr_eq_class)
  return eq_classes


# Read in RNA-seq data in zip FASTA format
import gzip
with gzip.open("reads.fasta.gz", "rt") as f:
    # Initialize dictionary to keep track of equivalence class counts
    eq_class_counts = {}

    # Iterate over each read in the file
    seq_id = None
    seq = ""
    for line in f:
        if line.startswith(">"):  # Start of a new sequence
            if seq_id is not None:  # Process the previous sequence
                # Get equivalence classes for the sequence
                equiv_classes = get_equivalence_classes(seq, hash_table, 31)
                my_tuple = tuple(equiv_classes)
                # Update counts for each equivalence class
                if my_tuple in eq_class_counts:
                  eq_class_counts[my_tuple] += 1
                else:
                  eq_class_counts[my_tuple] = 1
            seq_id = line.strip()[1:]
            seq = ""
        else:  # Sequence line
            seq += line.strip().upper()

    # Process the last sequence
    equiv_classes = get_equivalence_classes(seq, hash_table, 31)
    my_tuple = tuple(equiv_classes)
    if my_tuple in eq_class_counts:
        eq_class_counts[my_tuple] += 1
    else:
        eq_class_counts[my_tuple] = 1

# @title
length = len(eq_class_counts)
print(length)

# @title
from tabulate import tabulate
rows = []
headers = ['Isoforms', 'Count', 'no of isoforms']
sorted_dict = dict(sorted(eq_class_counts.items(), key=lambda x: len(x[0])))


items = list(sorted_dict.items())[:5]  # get the first 5 key-value pairs
last_15_items = list(sorted_dict.items())[-5:]
all_items = list(sorted_dict.items())

for key, value in items:
    rows.append([key, value, len(key)])

table = tabulate(rows, headers=headers, tablefmt='fancy_grid')
print(table)

# @title
import csv
from tabulate import tabulate

# Convert dictionary to list of lists
rows = [[value, len(key), key] for key, value in sorted_dict.items()]

# Create table in pretty format
table = tabulate(rows, headers=['Count', 'Number of items in equivalence class', 'isoforms in equivalence class'], tablefmt='pretty')

# Export table to CSV file
with open('my_dict.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['Count', 'Number of items in equivalence class', 'isoforms in equivalence class'])
    for row in rows:
        writer.writerow(row)

# @title
size = []
count = []
sorted_dict = dict(sorted(eq_class_counts.items()))

items = list(sorted_dict.items())
for key, value in items:
    size.append(len(key))
    count.append(value)

new_size = size[1:]
new_count = count[1:]

plt.bar(size, count)
plt.xlabel('size of equivalence class')
plt.ylabel('read counts')
plt.title('size of the equivalence classes vs data mapping to them')
plt.show()

plt.bar(new_size, new_count)
plt.xlabel('size of equivalence class')
plt.ylabel('read counts')
plt.title('size of the equivalence classes vs data mapping to them without null set')
plt.show()